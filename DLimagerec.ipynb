{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cb47f-7198-44aa-8ac5-0a1203b6bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
    "    layers.MaxPool2D(pool_size=2),\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14a620-f1fa-4121-bcff-99a032e408bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Maximum Pooling\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
    "\n",
    "# Read image\n",
    "image_path = '../input/computer-vision-resources/car_feature.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.io.decode_jpeg(image)\n",
    "\n",
    "# Define kernel\n",
    "kernel = tf.constant([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "\n",
    "# Filter step\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    # we'll talk about these two in the next lesson!\n",
    "    strides=1,\n",
    "    padding='SAME'\n",
    ")\n",
    "\n",
    "# Detect step\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "# Show what we have so far\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(tf.squeeze(image), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Input')\n",
    "plt.subplot(132)\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.title('Filter')\n",
    "plt.subplot(133)\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.title('Detect')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0b1c3-12b7-4d12-a3bf-af4803b79240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use another one of the functions in tf.nn to apply the pooling step, tf.nn.pool. This is a Python function that does the same thing as the MaxPool2D layer you use when model building, but, being a simple function, is easier to use directly.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "image_condense = tf.nn.pool(\n",
    "    input=image_detect, # image in the Detect step above\n",
    "    window_shape=(2, 2),\n",
    "    pooling_type='MAX',\n",
    "    # we'll see what these do in the next lesson!\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(tf.squeeze(image_condense))\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128a8b6-610b-4005-9625-01a31c27f20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e157566-742e-4e1a-9b60-9e8d4260337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import learntools.computer_vision.visiontools as visiontools\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c1a3d-f6ff-4845-901a-fb975093d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "image_path = '../input/computer-vision-resources/car_illus.jpg'\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.io.decode_jpeg(image, channels=1)\n",
    "image = tf.image.resize(image, size=[400, 400])\n",
    "\n",
    "# Embossing kernel\n",
    "kernel = tf.constant([\n",
    "    [-2, -1, 0],\n",
    "    [-1, 1, 1],\n",
    "    [0, 1, 2],\n",
    "])\n",
    "\n",
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)\n",
    "\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "\n",
    "# Show what we have so far\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(tf.squeeze(image), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Input')\n",
    "plt.subplot(132)\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.title('Filter')\n",
    "plt.subplot(133)\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.title('Detect')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae8845-03f1-4304-ab7f-2888cee0c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Pooling to Condense\n",
    "\n",
    "# YOUR CODE HERE\n",
    "image_condense = tf.nn.pool(\n",
    "    input=image_detect,\n",
    "    window_shape=(2, 2),\n",
    "    pooling_type='MAX',\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec006608-2dc1-45f2-8954-da3d81004f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what maximum pooling did to the feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54470b19-08b7-40e8-91f2-2aa461a8f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.title(\"Detect (ReLU)\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(tf.squeeze(image_condense))\n",
    "plt.axis('off')\n",
    "plt.title(\"Condense (MaxPool)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a75dc-c82a-46c3-9b98-a02c7e8c133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This next code cell will randomly apply a small shift to a circle and then condense the image several times with maximum pooling. \n",
    "# Run the cell once and make note of the image that results at the end.\n",
    "\n",
    "REPEATS = 4\n",
    "SIZE = [64, 64]\n",
    "\n",
    "# Create a randomly shifted circle\n",
    "image = visiontools.circle(SIZE, r_shrink=4, val=1)\n",
    "image = tf.expand_dims(image, axis=-1)\n",
    "image = visiontools.random_transform(image, jitter=3, fill_method='replicate')\n",
    "image = tf.squeeze(image)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, REPEATS+1, 1)\n",
    "plt.imshow(image, vmin=0, vmax=1)\n",
    "plt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\n",
    "plt.axis('off')\n",
    "\n",
    "# Now condense with maximum pooling several times\n",
    "for i in range(REPEATS):\n",
    "    ax = plt.subplot(1, REPEATS+1, i+2)\n",
    "    image = tf.reshape(image, [1, *image.shape, 1])\n",
    "    image = tf.nn.pool(image, window_shape=(2,2), strides=(2, 2), padding='SAME', pooling_type='MAX')\n",
    "    image = tf.squeeze(image)\n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[0], image.shape[1]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89ac58-09cc-4f02-8140-421b7f4e1352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e5037-ac0f-473d-a4e8-5b0d3a79f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Invariance\n",
    "\n",
    "feature_maps = [visiontools.random_map([5, 5], scale=0.1, decay_power=4) for _ in range(8)]\n",
    "\n",
    "gs = gridspec.GridSpec(1, 8, wspace=0.01, hspace=0.01)\n",
    "plt.figure(figsize=(18, 2))\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.imshow(feature_map, vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Feature Maps', size=18, weight='bold', y=1.1)\n",
    "plt.show()\n",
    "\n",
    "# reformat for TensorFlow\n",
    "feature_maps_tf = [tf.reshape(feature_map, [1, *feature_map.shape, 1])\n",
    "                   for feature_map in feature_maps]\n",
    "\n",
    "global_avg_pool = tf.keras.layers.GlobalAvgPool2D()\n",
    "pooled_maps = [global_avg_pool(feature_map) for feature_map in feature_maps_tf]\n",
    "img = np.array(pooled_maps)[:,:,0].T\n",
    "\n",
    "plt.imshow(img, vmin=0, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.title('Pooled Feature Maps')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa057f4-473d-4c72-aada-b3535fc61090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65535e04-6761-4104-b2c7-60b1d1fd3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pass some images from our Car or Truck dataset through VGG16 and examine the features that result after pooling. First run this cell to define the model and load the dataset.\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Load VGG16\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    # Attach a global average pooling layer after the base\n",
    "    layers.GlobalAvgPool2D(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "ds = image_dataset_from_directory(\n",
    "    '../input/car-or-truck/train',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "ds_iter = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1a85a-14b3-45ef-b127-5a6294cc7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Notice how we've attached a GlobalAvgPool2D layer after the pretrained VGG16 base. Ordinarily, VGG16 will produce 512 feature maps for each image. The GlobalAvgPool2D layer reduces each of these to a single value, an \"average pixel\", if you like.\n",
    "\n",
    "This next cell will run an image from the Car or Truck dataset through VGG16 and show you the 512 average pixels created by GlobalAvgPool2D. Run the cell a few times and observe the pixels produced by cars versus the pixels produced by trucks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e92d39-9cc6-4b78-aa00-5e47f7dea9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = next(ds_iter)\n",
    "\n",
    "car_tf = tf.image.resize(car[0], size=[128, 128])\n",
    "car_features = model(car_tf)\n",
    "car_features = tf.reshape(car_features, shape=(16, 32))\n",
    "label = int(tf.squeeze(car[1]).numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(tf.squeeze(car[0]))\n",
    "plt.axis('off')\n",
    "plt.title([\"Car\", \"Truck\"][label])\n",
    "plt.subplot(122)\n",
    "plt.imshow(car_features)\n",
    "plt.title('Pooled Feature Maps')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c41410-c39d-4e61-a0ab-e4e0b3cef8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b0aef-0ef1-4c4b-9a3a-36d54c8246d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from skimage import draw, transform\n",
    "\n",
    "def circle(size, val=None, r_shrink=0):\n",
    "    circle = np.zeros([size[0]+1, size[1]+1])\n",
    "    rr, cc = draw.circle_perimeter(\n",
    "        size[0]//2, size[1]//2,\n",
    "        radius=size[0]//2 - r_shrink,\n",
    "        shape=[size[0]+1, size[1]+1],\n",
    "    )\n",
    "    if val is None:\n",
    "        circle[rr, cc] = np.random.uniform(size=circle.shape)[rr, cc]\n",
    "    else:\n",
    "        circle[rr, cc] = val\n",
    "    circle = transform.resize(circle, size, order=0)\n",
    "    return circle\n",
    "\n",
    "def show_kernel(kernel, label=True, digits=None, text_size=28):\n",
    "    # Format kernel\n",
    "    kernel = np.array(kernel)\n",
    "    if digits is not None:\n",
    "        kernel = kernel.round(digits)\n",
    "\n",
    "    # Plot kernel\n",
    "    cmap = plt.get_cmap('Blues_r')\n",
    "    plt.imshow(kernel, cmap=cmap)\n",
    "    rows, cols = kernel.shape\n",
    "    thresh = (kernel.max()+kernel.min())/2\n",
    "    # Optionally, add value labels\n",
    "    if label:\n",
    "        for i, j in product(range(rows), range(cols)):\n",
    "            val = kernel[i, j]\n",
    "            color = cmap(0) if val > thresh else cmap(255)\n",
    "            plt.text(j, i, val, \n",
    "                     color=color, size=text_size,\n",
    "                     horizontalalignment='center', verticalalignment='center')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "def show_extraction(image,\n",
    "                    kernel,\n",
    "                    conv_stride=1,\n",
    "                    conv_padding='valid',\n",
    "                    activation='relu',\n",
    "                    pool_size=2,\n",
    "                    pool_stride=2,\n",
    "                    pool_padding='same',\n",
    "                    figsize=(10, 10),\n",
    "                    subplot_shape=(2, 2),\n",
    "                    ops=['Input', 'Filter', 'Detect', 'Condense'],\n",
    "                    gamma=1.0):\n",
    "    # Create Layers\n",
    "    model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=1,\n",
    "                        kernel_size=kernel.shape,\n",
    "                        strides=conv_stride,\n",
    "                        padding=conv_padding,\n",
    "                        use_bias=False,\n",
    "                        input_shape=image.shape,\n",
    "                    ),\n",
    "                    tf.keras.layers.Activation(activation),\n",
    "                    tf.keras.layers.MaxPool2D(\n",
    "                        pool_size=pool_size,\n",
    "                        strides=pool_stride,\n",
    "                        padding=pool_padding,\n",
    "                    ),\n",
    "                   ])\n",
    "\n",
    "    layer_filter, layer_detect, layer_condense = model.layers\n",
    "    kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "    layer_filter.set_weights([kernel])\n",
    "\n",
    "    # Format for TF\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32) \n",
    "    \n",
    "    # Extract Feature\n",
    "    image_filter = layer_filter(image)\n",
    "    image_detect = layer_detect(image_filter)\n",
    "    image_condense = layer_condense(image_detect)\n",
    "        images = {}\n",
    "    if 'Input' in ops:\n",
    "        images.update({'Input': (image, 1.0)})\n",
    "    if 'Filter' in ops:\n",
    "        images.update({'Filter': (image_filter, 1.0)})\n",
    "    if 'Detect' in ops:\n",
    "        images.update({'Detect': (image_detect, gamma)})\n",
    "    if 'Condense' in ops:\n",
    "        images.update({'Condense': (image_condense, gamma)})\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, title in enumerate(ops):\n",
    "        image, gamma = images[title]\n",
    "        plt.subplot(*subplot_shape, i+1)\n",
    "        plt.imshow(tf.image.adjust_gamma(tf.squeeze(image), gamma))\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581727d0-91fc-4236-ba88-1c75f08f05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''There are two additional parameters affecting both convolution and pooling layers -- these are the strides of the window and whether to use padding at the image edges. The strides parameter says how far the window should move at each step, and the padding parameter describes how we handle the pixels at the edges of the input.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b35d80-6fd6-4d6a-80de-251d7e0e999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With these two parameters, defining the two layers becomes:\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(filters=64,\n",
    "                  kernel_size=3,\n",
    "                  strides=1,\n",
    "                  padding='same',\n",
    "                  activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2,\n",
    "                     strides=1,\n",
    "                     padding='same')\n",
    "    # More layers follow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5131e3-f9e0-4f43-b772-2a55f43592e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring Sliding Windows\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "image = circle([64, 64], val=1.0, r_shrink=3)\n",
    "image = tf.reshape(image, [*image.shape, 1])\n",
    "# Bottom sobel\n",
    "kernel = tf.constant(\n",
    "    [[-1, -2, -1],\n",
    "     [0, 0, 0],\n",
    "     [1, 2, 1]],\n",
    ")\n",
    "\n",
    "show_kernel(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1c34b-a8ad-4044-8ec5-912ab1ac2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_extraction(\n",
    "    image, kernel,\n",
    "\n",
    "    # Window parameters\n",
    "    conv_stride=1,\n",
    "    pool_size=2,\n",
    "    pool_stride=2,\n",
    "\n",
    "    subplot_shape=(1, 4),\n",
    "    figsize=(14, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b95894-9195-4649-84e9-8ee0a238cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_extraction(\n",
    "    image, kernel,\n",
    "\n",
    "    # Window parameters\n",
    "    conv_stride=3,\n",
    "    pool_size=2,\n",
    "    pool_stride=2,\n",
    "\n",
    "    subplot_shape=(1, 4),\n",
    "    figsize=(14, 6),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b68a2-6e66-424b-af12-3f6e986d8bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a6c26-b73c-4e79-9a8d-0c73fe0dec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b5728-c9c9-4276-afa7-8935368b6bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0d47c-af20-49e4-9257-9f126b35d2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1919d40-c7b5-46c2-af44-d6be6c7747c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
